{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda10dbb-8943-4f53-868a-46977ea4824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b273f3-1942-4141-8f1c-c16f585f4679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preference dataset\n",
    "dataset = load_dataset(\"Dahoas/full-hh-rlhf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0970f63f-e8e6-4bb3-a9cc-697437519ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "''# Preprocess\n",
    "def preprocess_data(example):\n",
    "    return {\"text\": example[\"chosen\"], \"label\": float(1)}\n",
    "\n",
    "def preprocess_rejected(example):\n",
    "    return {\"text\": example[\"rejected\"], \"label\": float(0)}\n",
    "\n",
    "\n",
    "chosen_dataset = dataset[\"train\"].map(preprocess_data)\n",
    "rejected_dataset = dataset[\"train\"].map(preprocess_rejected)\n",
    "\n",
    "# Correctly merge them\n",
    "reward_dataset = concatenate_datasets([chosen_dataset, rejected_dataset])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdd53bf-29f6-4a04-9298-8c8bd25ca511",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9c9c9f-6ca9-4f77-9ed5-f82422b7a92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reward_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d348a248-3f1d-4827-8edb-89f9af1bf411",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(reward_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e352b7e8-62cb-4433-b306-b40c502b2e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base model and tokenizer\n",
    "base_model_name = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(base_model_name, num_labels=1)\n",
    "\n",
    "# Apply LoRA to model\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"query\", \"key\", \"value\", \"dense\", \"intermediate.dense\", \"output.dense\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# Tokenize dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "reward_dataset = reward_dataset.map(tokenize_function, batched=True)\n",
    "reward_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7429f979-c7c4-496c-8c40-32fa1432ac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_dataset_small = reward_dataset.shuffle(seed=42).select(range(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d8409f-472e-47ea-bbf0-c3c2f0978a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_dataset_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a58e8b-7cbd-41da-9a0b-90280ab738c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lora_reward_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=128,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\",\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=reward_dataset_small,\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8856280-b4b6-41ef-b8ed-3096b08d6c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./lora_reward_model-final\", save_adapter=True)\n",
    "tokenizer.save_pretrained(\"./lora_reward_model-final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa464a-f139-471b-ac6e-400cf7346c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f617a41-ef2a-4b2d-af2d-10140907757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Explain the theory of relativity.\"\n",
    "good_response = \"Let's think step-by-step. Relativity consists of two theories by Einstein: special and general relativity...\"\n",
    "bad_response = \"It's something about fast cars or something.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053a8f30-8ad6-40d3-a132-f7578020749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbe637f-0fa8-4563-b170-712377cda37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5809a74b-1cf4-4d71-bc88-067e52487d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = prompt + \"\\n\" + good_response\n",
    "inputs = tokenizer(full_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4586ee-a85d-4d33-9185-af965c7dfc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783b4306-fc14-4c7e-a48d-222db59a861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = prompt + \"\\n\" + bad_response\n",
    "inputs = tokenizer(full_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf1ec2a-6975-49b6-8190-960eee52c8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb336c39-a836-4756-be0e-449658274620",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sigmoid(torch.tensor([0.521, 0.4998]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f8d16b-d2e9-4d1b-ae6d-bb5037c67542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"OpenAssistant/reward-model-deberta-v3-large\")\n",
    "reward_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"OpenAssistant/reward-model-deberta-v3-large\",\n",
    "    num_labels=1\n",
    ").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "reward_model.eval()\n",
    "\n",
    "# Scoring function\n",
    "def score_response(prompt, response, model, tokenizer):\n",
    "    full_text = prompt + \"\\n\" + response\n",
    "    inputs = tokenizer(full_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        score = outputs.logits.squeeze().item()\n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf391c2-7e60-4ddc-99f9-c4a55ee60081",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "good_score = score_response(prompt, good_response, reward_model, tokenizer)\n",
    "bad_score = score_response(prompt, bad_response, reward_model, tokenizer)\n",
    "\n",
    "print(f\"✅ Good Response Score: {good_score:.4f}\")\n",
    "print(f\"❌ Bad Response Score: {bad_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20265b8a-c3af-4ab2-b9b8-1ff6d71d9dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sigmoid(torch.tensor([good_score, bad_score]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fa7cad-4cc5-4764-827a-79567f9e2a14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
